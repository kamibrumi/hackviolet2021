{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "\n",
    "# import plotting libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn') # pretty matplotlib plots\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set('notebook', style='whitegrid', font_scale=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_DIR = 'data/'\n",
    "#x_tr_M = np.loadtxt(os.path.join(DATA_DIR, 'SVI2018_US_COUNTY.csv'), delimiter=',', skiprows=1)\n",
    "\n",
    "data_svi2018_us_per_county = pd.read_csv(\"data/SVI2018_US_COUNTY.csv\") \n",
    "data_svi2018_us_per_county.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_covid_cases_deaths_county = pd.read_csv(\"data/covid_cases_deaths_county.csv\", dtype={\"fips\": str}, parse_dates=['date']) \n",
    "data_covid_cases_deaths_county.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(np.asarray([data_covid_cases_deaths_county['deaths']>10000.0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_df = data_covid_cases_deaths_county[data_covid_cases_deaths_county['date'] == '2021-01-20']\n",
    "  \n",
    "rslt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_covid_cases_deaths_county['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-owner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "foster-abortion",
   "metadata": {},
   "source": [
    "# GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "original-april",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3218,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aparently there are nans in this list but I cannot find them using numpy.isnan(myarray).any() so I remove them by doing:\n",
    "arr2 = np.asarray([int(x) for x in arr if str(x) != 'nan'])\n",
    "arr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "fst_day = max(data_covid_cases_deaths_county['date']) # the earliest day in the dataset\n",
    "fst_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_fst_day_df = data_covid_cases_deaths_county[data_covid_cases_deaths_county['date'] == fst_day]\n",
    "rslt_fst_day_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_fips_fst_day = np.asarray([fips for fips in rslt_fst_day_df['fips'].unique()])\n",
    "print(unique_fips_fst_day.shape)\n",
    "unique_fips_fst_day= np.asarray([x for x in unique_fips_fst_day if str(x) != 'nan']) # converting to int and removing nans\n",
    "print(unique_fips_fst_day.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_fips_fst_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now adding a column with integer identificator starting from 0\n",
    "ids_nodes = np.arange(unique_fips_fst_day.shape[0])\n",
    "ids_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "death_per_county = list()\n",
    "for _id in unique_fips_fst_day:\n",
    "    n_deaths = rslt_fst_day_df.loc[rslt_fst_day_df['fips'] == _id, 'deaths']\n",
    "    if (n_deaths.shape[0] == 0):\n",
    "        death_per_county.append(0.0)\n",
    "    else:\n",
    "        death_per_county.append(n_deaths.to_numpy()[0])\n",
    "            \n",
    "\n",
    "death_per_county = np.asarray(death_per_county, dtype = np.float64)\n",
    "death_per_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_fst_day_df.loc[rslt_fst_day_df['fips'] == '1001', 'deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change fips to be ints instead of strings so we can better manage the edges later\n",
    "unique_fips_fst_day = unique_fips_fst_day.astype(np.int64)\n",
    "unique_fips_fst_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can put together id, fips and deaths in a dataframe\n",
    "stack = np.hstack([ids_nodes.reshape((ids_nodes.shape[0],1)), unique_fips_fst_day.reshape((ids_nodes.shape[0],1)), death_per_county.reshape((ids_nodes.shape[0],1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_nodes.reshape((ids_nodes.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df = pd.DataFrame(data=stack, columns=[\"id\", \"fips\", \"deaths\"])\n",
    "print(nodes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the above is the data we are going to use for our nodes (1st layer).\n",
    "# now let's construct the edges data. We will take it from the counties adjacency data\n",
    "\n",
    "county_adjacency_df = pd.read_csv(\"data/county_adjacency2010.csv\", dtype={\"fips\": str}) \n",
    "county_adjacency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_adjacency_only_fips = county_adjacency_df[[\"fipscounty\", \"fipsneighbor\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the edges that are linking two different loops (we're avoiding loops)\n",
    "county_adjacency_only_fips = county_adjacency_only_fips[county_adjacency_only_fips['fipscounty'] != county_adjacency_only_fips['fipsneighbor']]\n",
    "county_adjacency_only_fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "fipscouty = county_adjacency_only_fips['fipscounty'].to_numpy()\n",
    "fipscouty.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "fipsneighbor = county_adjacency_only_fips['fipsneighbor'].to_numpy()\n",
    "fipsneighbor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# associating the ids to the source and destination nodes that we assigned when creating the nodes dataframe\n",
    "ids_src_nodes = list()\n",
    "ids_dst_nodes = list()\n",
    "for i in range(fipscouty.shape[0]):\n",
    "    id_to_append_src = nodes_df.loc[nodes_df['fips'] == fipscouty[i], 'id'].to_numpy()\n",
    "    id_to_append_dst = nodes_df.loc[nodes_df['fips'] == fipsneighbor[i], 'id'].to_numpy()\n",
    "    \n",
    "    if (id_to_append_src.shape[0] != 0 and id_to_append_dst.shape[0] != 0):\n",
    "        ids_src_nodes.append(id_to_append_src[0])\n",
    "        ids_dst_nodes.append(id_to_append_dst[0])\n",
    "    \n",
    "print(ids_src_nodes)\n",
    "print('--')\n",
    "print(ids_dst_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_src_nodes = np.asarray(ids_src_nodes, dtype=np.int64)\n",
    "ids_dst_nodes = np.asarray(ids_dst_nodes, dtype=np.int64)\n",
    "\n",
    "stack_edges = np.hstack([ids_src_nodes.reshape((ids_src_nodes.shape[0],1)), ids_dst_nodes.reshape((ids_dst_nodes.shape[0],1))])\n",
    "edges_df = pd.DataFrame(data=stack_edges, columns=[\"src\", \"dst\"])\n",
    "edges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have fewer numbers since there were counties ids in the adjacency dataframe that didn't match any county in\n",
    "# the nodes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "\n",
    "# now let's create the dgl graph\n",
    "src = edges_df['src'].to_numpy()\n",
    "dst = edges_df['dst'].to_numpy()\n",
    "\n",
    "# Create a DGL graph from a pair of numpy arrays\n",
    "g = dgl.graph((src, dst))\n",
    "\n",
    "# Print a graph gives some meta information such as number of nodes and edges.\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# Since the actual graph is undirected, we convert it for visualization\n",
    "# purpose.\n",
    "nx_g = g.to_networkx().to_undirected()\n",
    "# Kamada-Kawaii layout usually looks pretty for arbitrary graphs\n",
    "pos = nx.kamada_kawai_layout(nx_g)\n",
    "nx.draw(nx_g, pos, with_labels=True, node_color=[[.7, .7, .7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df['deaths'].to_numpy() # to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now I will load the node features, that is, the number of deaths.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Prepare the age node feature\n",
    "max_n_deaths = np.nanmax(nodes_df['deaths'].to_numpy())\n",
    "deaths = torch.tensor(nodes_df['deaths'].to_numpy()).float() / max_n_deaths\n",
    "print(deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed the features to graph\n",
    "g.ndata['deaths'] = deaths # we are setting one of the keys of the ndata dictionary to be age with value age, which we created above.\n",
    "print(g) # in the output, the shape=() represents the feature shape. The features in this case is the float that represents the age of each one of the members of the club."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a copy of the nodes df and add multiple layers of temporal data.\n",
    "# don't take the first day when covid appeared, but sometime when \n",
    "nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "generic-positive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3206,)\n",
      "(3205,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fips</th>\n",
       "      <th>deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>3213.0</td>\n",
       "      <td>56037.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>3214.0</td>\n",
       "      <td>56039.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>3215.0</td>\n",
       "      <td>56041.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3216</th>\n",
       "      <td>3216.0</td>\n",
       "      <td>56043.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>3217.0</td>\n",
       "      <td>56045.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3218 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     fips  deaths\n",
       "0        0.0   1001.0    69.0\n",
       "1        1.0   1003.0   224.0\n",
       "2        2.0   1005.0    40.0\n",
       "3        3.0   1007.0    51.0\n",
       "4        4.0   1009.0    98.0\n",
       "...      ...      ...     ...\n",
       "3213  3213.0  56037.0    32.0\n",
       "3214  3214.0  56039.0     6.0\n",
       "3215  3215.0  56041.0    12.0\n",
       "3216  3216.0  56043.0    25.0\n",
       "3217  3217.0  56045.0     4.0\n",
       "\n",
       "[3218 rows x 3 columns]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we're gonna create the nodes from day Sept 14 and then add on top of that dataframe\n",
    "#def create_df_nodes_day(day_date, start_id):\n",
    "first_day_df = pd.to_datetime(['2020-09-14'])\n",
    "first_day = np.array(first_day_df, dtype= np.datetime64)[0]\n",
    "\n",
    "first_day_df = data_covid_cases_deaths_county[data_covid_cases_deaths_county['date'] == first_day]\n",
    "\n",
    "#removing duplicates\n",
    "unique_fips_first_day = np.asarray([fips for fips in first_day_df['fips'].unique()])\n",
    "print(unique_fips_first_day.shape)\n",
    "\n",
    "# removing nans\n",
    "unique_fips_first_day= np.asarray([x for x in unique_fips_first_day if str(x) != 'nan']) \n",
    "print(unique_fips_first_day.shape)\n",
    "\n",
    "# now adding a column with integer identificator starting from 0\n",
    "ids_nodes = np.arange(unique_fips_first_day.shape[0])\n",
    "\n",
    "#computing and crafting the number of deaths per county\n",
    "death_per_county = list()\n",
    "for _fips in unique_fips_first_day:\n",
    "    n_deaths = first_day_df.loc[first_day_df['fips'] == _fips, 'deaths']\n",
    "    if (n_deaths.shape[0] == 0):\n",
    "        death_per_county.append(0.0)\n",
    "    else:\n",
    "        death_per_county.append(n_deaths.to_numpy()[0])\n",
    "            \n",
    "\n",
    "death_per_county = np.asarray(death_per_county, dtype = np.float64)\n",
    "\n",
    "# change fips to be ints instead of strings so we can better manage the edges later\n",
    "unique_fips_first_day = unique_fips_first_day.astype(np.int64)\n",
    "\n",
    "# now we can put together id, fips and deaths in a dataframe\n",
    "stack_14 = np.hstack([ids_nodes.reshape((ids_nodes.shape[0],1)), unique_fips_first_day.reshape((ids_nodes.shape[0],1)), death_per_county.reshape((ids_nodes.shape[0],1))])\n",
    "\n",
    "\n",
    "nodes_14_df = pd.DataFrame(data=stack, columns=[\"id\", \"fips\", \"deaths\"])\n",
    "nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "broad-stand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2020-09-15T00:00:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#days_df =pd.to_datetime(['2020-09-15', '2020-09-16', '2020-09-17', '2020-09-19'])\n",
    "days_df =pd.to_datetime(['2020-09-15'])\n",
    "days_np_arr = np.array(days_df, dtype= np.datetime64)\n",
    "\n",
    "days_np_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "controversial-enlargement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date      county    state   fips  cases  deaths\n",
      "534478 2020-09-15     Autauga  Alabama  01001   1601    24.0\n",
      "534479 2020-09-15     Baldwin  Alabama  01003   4992    47.0\n",
      "534480 2020-09-15     Barbour  Alabama  01005    806     7.0\n",
      "534481 2020-09-15        Bibb  Alabama  01007    611     9.0\n",
      "534482 2020-09-15      Blount  Alabama  01009   1475    13.0\n",
      "...           ...         ...      ...    ...    ...     ...\n",
      "537709 2020-09-15  Sweetwater  Wyoming  56037    317     2.0\n",
      "537710 2020-09-15       Teton  Wyoming  56039    478     1.0\n",
      "537711 2020-09-15       Uinta  Wyoming  56041    312     2.0\n",
      "537712 2020-09-15    Washakie  Wyoming  56043    110     6.0\n",
      "537713 2020-09-15      Weston  Wyoming  56045     23     0.0\n",
      "\n",
      "[3236 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "for day in days_np_arr:\n",
    "    rslt_day_i_df = data_covid_cases_deaths_county[data_covid_cases_deaths_county['date'] == day]\n",
    "    print(rslt_day_i_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more ideas:\n",
    "# add also number of cases! not only deaths\n",
    "# in order to give the doctors intuition on where they should send personnel\n",
    "# and resources to treat the patients.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
