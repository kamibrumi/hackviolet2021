{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "\n",
    "# import plotting libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn') # pretty matplotlib plots\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set('notebook', style='whitegrid', font_scale=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_DIR = 'data/'\n",
    "#x_tr_M = np.loadtxt(os.path.join(DATA_DIR, 'SVI2018_US_COUNTY.csv'), delimiter=',', skiprows=1)\n",
    "\n",
    "data_svi2018_us_per_county = pd.read_csv(\"data/SVI2018_US_COUNTY.csv\") \n",
    "data_svi2018_us_per_county.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_covid_cases_deaths_county = pd.read_csv(\"data/covid_cases_deaths_county.csv\", dtype={\"fips\": str}, parse_dates=['date']) \n",
    "data_covid_cases_deaths_county.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(np.asarray([data_covid_cases_deaths_county['deaths']>10000.0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_df = data_covid_cases_deaths_county[data_covid_cases_deaths_county['date'] == '2021-01-20']\n",
    "  \n",
    "rslt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_covid_cases_deaths_county['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-owner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "liberal-catering",
   "metadata": {},
   "source": [
    "# GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "fst_day = max(data_covid_cases_deaths_county['date']) # the earliest day in the dataset\n",
    "fst_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_fst_day_df = data_covid_cases_deaths_county[data_covid_cases_deaths_county['date'] == fst_day]\n",
    "rslt_fst_day_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_fips_fst_day = np.asarray([fips for fips in rslt_fst_day_df['fips'].unique()])\n",
    "print(unique_fips_fst_day.shape)\n",
    "unique_fips_fst_day= np.asarray([x for x in unique_fips_fst_day if str(x) != 'nan']) # converting to int and removing nans\n",
    "print(unique_fips_fst_day.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_fips_fst_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now adding a column with integer identificator starting from 0\n",
    "ids_nodes = np.arange(unique_fips_fst_day.shape[0])\n",
    "ids_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "death_per_county = list()\n",
    "for _id in unique_fips_fst_day:\n",
    "    n_deaths = rslt_fst_day_df.loc[rslt_fst_day_df['fips'] == _id, 'deaths']\n",
    "    if (n_deaths.shape[0] == 0):\n",
    "        death_per_county.append(0.0)\n",
    "    else:\n",
    "        death_per_county.append(n_deaths.to_numpy()[0])\n",
    "            \n",
    "\n",
    "death_per_county = np.asarray(death_per_county, dtype = np.float64)\n",
    "death_per_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_fst_day_df.loc[rslt_fst_day_df['fips'] == '1001', 'deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change fips to be ints instead of strings so we can better manage the edges later\n",
    "unique_fips_fst_day = unique_fips_fst_day.astype(np.int64)\n",
    "unique_fips_fst_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can put together id, fips and deaths in a dataframe\n",
    "stack = np.hstack([ids_nodes.reshape((ids_nodes.shape[0],1)), unique_fips_fst_day.reshape((ids_nodes.shape[0],1)), death_per_county.reshape((ids_nodes.shape[0],1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_nodes.reshape((ids_nodes.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df = pd.DataFrame(data=stack, columns=[\"id\", \"fips\", \"deaths\"])\n",
    "print(nodes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the above is the data we are going to use for our nodes (1st layer).\n",
    "# now let's construct the edges data. We will take it from the counties adjacency data\n",
    "\n",
    "county_adjacency_df = pd.read_csv(\"data/county_adjacency2010.csv\", dtype={\"fips\": str}) \n",
    "county_adjacency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_adjacency_only_fips = county_adjacency_df[[\"fipscounty\", \"fipsneighbor\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the edges that are linking two different loops (we're avoiding loops)\n",
    "county_adjacency_only_fips = county_adjacency_only_fips[county_adjacency_only_fips['fipscounty'] != county_adjacency_only_fips['fipsneighbor']]\n",
    "county_adjacency_only_fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "fipscouty = county_adjacency_only_fips['fipscounty'].to_numpy()\n",
    "fipscouty.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "fipsneighbor = county_adjacency_only_fips['fipsneighbor'].to_numpy()\n",
    "fipsneighbor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# associating the ids to the source and destination nodes that we assigned when creating the nodes dataframe\n",
    "ids_src_nodes = list()\n",
    "ids_dst_nodes = list()\n",
    "for i in range(fipscouty.shape[0]):\n",
    "    id_to_append_src = nodes_df.loc[nodes_df['fips'] == fipscouty[i], 'id'].to_numpy()\n",
    "    id_to_append_dst = nodes_df.loc[nodes_df['fips'] == fipsneighbor[i], 'id'].to_numpy()\n",
    "    \n",
    "    if (id_to_append_src.shape[0] != 0 and id_to_append_dst.shape[0] != 0):\n",
    "        ids_src_nodes.append(id_to_append_src[0])\n",
    "        ids_dst_nodes.append(id_to_append_dst[0])\n",
    "    \n",
    "print(ids_src_nodes)\n",
    "print('--')\n",
    "print(ids_dst_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_src_nodes = np.asarray(ids_src_nodes, dtype=np.int64)\n",
    "ids_dst_nodes = np.asarray(ids_dst_nodes, dtype=np.int64)\n",
    "\n",
    "stack_edges = np.hstack([ids_src_nodes.reshape((ids_src_nodes.shape[0],1)), ids_dst_nodes.reshape((ids_dst_nodes.shape[0],1))])\n",
    "edges_df = pd.DataFrame(data=stack_edges, columns=[\"src\", \"dst\"])\n",
    "edges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have fewer numbers since there were counties ids in the adjacency dataframe that didn't match any county in\n",
    "# the nodes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "\n",
    "# now let's create the dgl graph\n",
    "src = edges_df['src'].to_numpy()\n",
    "dst = edges_df['dst'].to_numpy()\n",
    "\n",
    "# Create a DGL graph from a pair of numpy arrays\n",
    "g = dgl.graph((src, dst))\n",
    "\n",
    "# Print a graph gives some meta information such as number of nodes and edges.\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# Since the actual graph is undirected, we convert it for visualization\n",
    "# purpose.\n",
    "nx_g = g.to_networkx().to_undirected()\n",
    "# Kamada-Kawaii layout usually looks pretty for arbitrary graphs\n",
    "pos = nx.kamada_kawai_layout(nx_g)\n",
    "nx.draw(nx_g, pos, with_labels=True, node_color=[[.7, .7, .7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df['deaths'].to_numpy() # to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now I will load the node features, that is, the number of deaths.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Prepare the age node feature\n",
    "max_n_deaths = np.nanmax(nodes_df['deaths'].to_numpy())\n",
    "deaths = torch.tensor(nodes_df['deaths'].to_numpy()).float() / max_n_deaths\n",
    "print(deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed the features to graph\n",
    "g.ndata['deaths'] = deaths # we are setting one of the keys of the ndata dictionary to be age with value age, which we created above.\n",
    "print(g) # in the output, the shape=() represents the feature shape. The features in this case is the float that represents the age of each one of the members of the club."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a copy of the nodes df and add multiple layers of temporal data.\n",
    "# don't take the first day when covid appeared, but sometime when \n",
    "nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're gonna create the nodes from day Sept 14 and then add on top of that dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_df =pd.to_datetime(['2020-09-15', '2020-09-16', '2020-09-17', '2020-09-19'])\n",
    "days_np_arr = np.array(days_df, dtype= np.datetime64)\n",
    "\n",
    "days_np_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in days_np_arr:\n",
    "    rslt_day_i_df = data_covid_cases_deaths_county[data_covid_cases_deaths_county['date'] == day]\n",
    "    print(rslt_day_i_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more ideas:\n",
    "# add also number of cases! not only deaths\n",
    "# in order to give the doctors intuition on where they should send personnel\n",
    "# and resources to treat the patients.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
